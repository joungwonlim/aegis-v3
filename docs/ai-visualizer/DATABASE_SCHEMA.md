# Database Schema Specification

> **AI ÏãúÍ∞ÅÌôî ÏãúÏä§ÌÖú Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÏÑ§Í≥Ñ**

## üìã Î™©Ï∞®

1. [Í∞úÏöî](#Í∞úÏöî)
2. [ÌÖåÏù¥Î∏î Íµ¨Ï°∞](#ÌÖåÏù¥Î∏î-Íµ¨Ï°∞)
3. [Í¥ÄÍ≥Ñ Îã§Ïù¥Ïñ¥Í∑∏Îû®](#Í¥ÄÍ≥Ñ-Îã§Ïù¥Ïñ¥Í∑∏Îû®)
4. [Ïù∏Îç±Ïä§ Ï†ÑÎûµ](#Ïù∏Îç±Ïä§-Ï†ÑÎûµ)
5. [ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò](#ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò)

---

## Í∞úÏöî

### ÏÑ§Í≥Ñ ÏõêÏπô

| ÏõêÏπô | ÏÑ§Î™Ö |
|-----|------|
| **Ï†ïÍ∑úÌôî** | 3NF Ï§ÄÏàò, Îç∞Ïù¥ÌÑ∞ Ï§ëÎ≥µ ÏµúÏÜåÌôî |
| **ÏÑ±Îä•** | ÏßëÍ≥Ñ ÏøºÎ¶¨ ÏµúÏ†ÅÌôî, ÌååÌã∞ÏÖîÎãù Í≥†Î†§ |
| **ÌôïÏû•ÏÑ±** | JSONBÎ°ú Ïú†Ïó∞Ìïú Ïä§ÌÇ§Îßà |
| **ÌÉÄÏûÑÏ°¥** | Î™®Îì† timestampÎäî UTC |
| **UUID** | Primary KeyÎäî UUID v7 (ÏãúÍ∞Ñ Ï†ïÎ†¨) |

---

## ÌÖåÏù¥Î∏î Íµ¨Ï°∞

### 1. analysis_batches (Î∞∞Ïπò Ïã§Ìñâ)

```sql
-- Ìïú Î≤àÏùò Î∂ÑÏÑù ÏÇ¨Ïù¥ÌÅ¥ (2,500 ‚Üí 3 Ï¢ÖÎ™©)
CREATE TABLE analysis_batches (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    started_at TIMESTAMP NOT NULL DEFAULT NOW(),
    completed_at TIMESTAMP,
    status VARCHAR(20) NOT NULL DEFAULT 'RUNNING',
        -- RUNNING, COMPLETED, FAILED, PAUSED
    trigger_type VARCHAR(20) NOT NULL,
        -- SCHEDULED, MANUAL
    error_message TEXT,
    metadata JSONB,
        -- { "version": "3.0", "config": {...} }
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP NOT NULL DEFAULT NOW()
);

-- Ïù∏Îç±Ïä§
CREATE INDEX idx_batches_status ON analysis_batches(status);
CREATE INDEX idx_batches_started_at ON analysis_batches(started_at DESC);
CREATE INDEX idx_batches_trigger_type ON analysis_batches(trigger_type);

-- ÏΩîÎ©òÌä∏
COMMENT ON TABLE analysis_batches IS 'Î∞∞Ïπò Ïã§Ìñâ Îã®ÏúÑ';
COMMENT ON COLUMN analysis_batches.metadata IS 'Ïã§Ìñâ ÏÑ§Ï†ï Î∞è Î©îÌÉÄÏ†ïÎ≥¥';
```

**ÏòàÏãú Îç∞Ïù¥ÌÑ∞**:
```json
{
    "id": "01932b75-8f0a-7c40-b5d4-2e8f3a1b9c7e",
    "started_at": "2025-12-08T06:00:00Z",
    "completed_at": "2025-12-08T06:05:23Z",
    "status": "COMPLETED",
    "trigger_type": "SCHEDULED",
    "metadata": {
        "version": "3.0",
        "flash_model": "gemini-2.0-flash",
        "pro_model": "gemini-2.5-pro"
    }
}
```

---

### 2. signal_sources (Ïã†Ìò∏ ÏÜåÏä§ Ï†ïÏùò)

```sql
-- Í∏ÄÎ°úÎ≤å Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§ ÎßàÏä§ÌÑ∞ ÌÖåÏù¥Î∏î
CREATE TABLE signal_sources (
    id SERIAL PRIMARY KEY,
    source_code VARCHAR(50) UNIQUE NOT NULL,
        -- 'US_FED', 'US_SP500', 'EU_ECB', 'GOLD', 'WTI', etc.
    source_name VARCHAR(100) NOT NULL,
        -- 'ÎØ∏Íµ≠ Ïó∞Ï§Ä Í∏àÎ¶¨', 'S&P 500 ÏßÄÏàò', etc.
    category VARCHAR(50) NOT NULL,
        -- 'MACRO', 'COMMODITY', 'INDEX', 'CURRENCY', 'NEWS'
    region VARCHAR(50) NOT NULL,
        -- 'US', 'EU', 'ASIA', 'GLOBAL'
    icon VARCHAR(10),
        -- 'üá∫üá∏', 'ü•á', 'üõ¢Ô∏è', 'üí±'
    position_x FLOAT,
        -- ÏãúÍ∞ÅÌôî Í∏∞Î≥∏ X Ï¢åÌëú (0.0 ~ 1.0)
    position_y FLOAT,
        -- ÏãúÍ∞ÅÌôî Í∏∞Î≥∏ Y Ï¢åÌëú (0.0 ~ 1.0)
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP NOT NULL DEFAULT NOW()
);

-- Ïù∏Îç±Ïä§
CREATE INDEX idx_sources_category ON signal_sources(category);
CREATE INDEX idx_sources_region ON signal_sources(region);
CREATE INDEX idx_sources_active ON signal_sources(is_active) WHERE is_active = TRUE;

-- Ï¥àÍ∏∞ Îç∞Ïù¥ÌÑ∞ (ÏòàÏãú)
INSERT INTO signal_sources (source_code, source_name, category, region, icon, position_x, position_y) VALUES
    ('US_FED', 'ÎØ∏Íµ≠ Ïó∞Ï§Ä Í∏àÎ¶¨', 'MACRO', 'US', 'üá∫üá∏', 0.2, 0.3),
    ('US_SP500', 'S&P 500', 'INDEX', 'US', 'üìà', 0.25, 0.35),
    ('EU_ECB', 'Ïú†ÎüΩ Ï§ëÏïôÏùÄÌñâ', 'MACRO', 'EU', 'üá™üá∫', 0.4, 0.2),
    ('GOLD', 'Í∏à Í∞ÄÍ≤©', 'COMMODITY', 'GLOBAL', 'ü•á', 0.5, 0.5),
    ('WTI', 'WTI Ïú†Í∞Ä', 'COMMODITY', 'GLOBAL', 'üõ¢Ô∏è', 0.6, 0.5),
    ('COPPER', 'Íµ¨Î¶¨ Í∞ÄÍ≤©', 'COMMODITY', 'GLOBAL', 'üî∂', 0.65, 0.55),
    ('JP_NIKKEI', 'ÎãàÏºÄÏù¥ 225', 'INDEX', 'ASIA', 'üáØüáµ', 0.7, 0.3),
    ('CN_SSE', 'ÏÉÅÌï¥Ï¢ÖÌï©', 'INDEX', 'ASIA', 'üá®üá≥', 0.75, 0.4);
```

---

### 3. signal_logs (ÏàòÏßëÎêú Ïã†Ìò∏)

```sql
-- FetcherÍ∞Ä ÏàòÏßëÌïú Í∏ÄÎ°úÎ≤å Ïã†Ìò∏
CREATE TABLE signal_logs (
    id SERIAL PRIMARY KEY,
    batch_id UUID NOT NULL REFERENCES analysis_batches(id) ON DELETE CASCADE,
    source_code VARCHAR(50) NOT NULL REFERENCES signal_sources(source_code),
    signal_type VARCHAR(20) NOT NULL,
        -- 'NEWS', 'PRICE', 'INDICATOR', 'EVENT'
    title VARCHAR(500),
        -- Îâ¥Ïä§ Ï†úÎ™© or ÏßÄÌëúÎ™Ö
    content TEXT,
        -- Îâ¥Ïä§ Î≥∏Î¨∏ or ÏßÄÌëú ÏÑ§Î™Ö
    sentiment VARCHAR(20),
        -- 'POSITIVE', 'NEGATIVE', 'NEUTRAL'
    sentiment_score FLOAT,
        -- -1.0 (Îß§Ïö∞ Î∂ÄÏ†ï) ~ +1.0 (Îß§Ïö∞ Í∏çÏ†ï)
    impact_level VARCHAR(20),
        -- 'HIGH', 'MEDIUM', 'LOW'
    raw_value JSONB,
        -- ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞ (Ïú†Ïó∞Ìïú Ï†ÄÏû•)
    fetched_at TIMESTAMP NOT NULL DEFAULT NOW()
);

-- Ïù∏Îç±Ïä§
CREATE INDEX idx_signals_batch ON signal_logs(batch_id);
CREATE INDEX idx_signals_source ON signal_logs(source_code);
CREATE INDEX idx_signals_sentiment ON signal_logs(batch_id, sentiment);
CREATE INDEX idx_signals_impact ON signal_logs(batch_id, impact_level);

-- ÏòàÏãú Îç∞Ïù¥ÌÑ∞
INSERT INTO signal_logs (batch_id, source_code, signal_type, title, sentiment, sentiment_score, impact_level) VALUES
    ('01932b75-8f0a-7c40-b5d4-2e8f3a1b9c7e', 'US_FED', 'INDICATOR', 'Fed Í∏àÎ¶¨ ÎèôÍ≤∞', 'POSITIVE', 0.7, 'HIGH'),
    ('01932b75-8f0a-7c40-b5d4-2e8f3a1b9c7e', 'WTI', 'PRICE', 'WTI 5% Í∏âÎì±', 'NEGATIVE', -0.5, 'MEDIUM'),
    ('01932b75-8f0a-7c40-b5d4-2e8f3a1b9c7e', 'GOLD', 'PRICE', 'Í∏à Í∞ÄÍ≤© ÏÇ¨ÏÉÅ ÏµúÍ≥†Ïπò', 'POSITIVE', 0.9, 'HIGH');
```

---

### 4. analysis_steps (Îã®Í≥ÑÎ≥Ñ ÏßÑÌñâ)

```sql
-- Î∞∞Ïπò ÎÇ¥ Í∞Å Îã®Í≥Ñ (FETCH, FLASH_FILTER, PRO_REASON)
CREATE TABLE analysis_steps (
    id SERIAL PRIMARY KEY,
    batch_id UUID NOT NULL REFERENCES analysis_batches(id) ON DELETE CASCADE,
    step_name VARCHAR(50) NOT NULL,
        -- 'FETCH', 'FLASH_FILTER', 'PRO_REASON'
    model_used VARCHAR(50),
        -- 'gemini-2.0-flash-exp', 'gemini-2.5-pro-preview'
    input_count INT,
        -- ÏûÖÎ†• Ï¢ÖÎ™©/Ïã†Ìò∏ Ïàò
    output_count INT,
        -- Ï∂úÎ†• Ï¢ÖÎ™©/Ïã†Ìò∏ Ïàò
    processing_time_ms INT,
        -- Ï≤òÎ¶¨ ÏãúÍ∞Ñ (Î∞ÄÎ¶¨Ï¥à)
    started_at TIMESTAMP NOT NULL DEFAULT NOW(),
    completed_at TIMESTAMP,
    error_message TEXT,
    metadata JSONB
);

-- Ïù∏Îç±Ïä§
CREATE INDEX idx_steps_batch ON analysis_steps(batch_id);
CREATE INDEX idx_steps_name ON analysis_steps(step_name);
CREATE INDEX idx_steps_started_at ON analysis_steps(started_at DESC);

-- ÏòàÏãú Îç∞Ïù¥ÌÑ∞
INSERT INTO analysis_steps (batch_id, step_name, model_used, input_count, output_count, processing_time_ms, started_at, completed_at) VALUES
    ('01932b75-8f0a-7c40-b5d4-2e8f3a1b9c7e', 'FETCH', NULL, 0, 2500, 8500, '2025-12-08T06:00:00Z', '2025-12-08T06:00:08Z'),
    ('01932b75-8f0a-7c40-b5d4-2e8f3a1b9c7e', 'FLASH_FILTER', 'gemini-2.0-flash-exp', 2500, 50, 120000, '2025-12-08T06:00:08Z', '2025-12-08T06:02:08Z'),
    ('01932b75-8f0a-7c40-b5d4-2e8f3a1b9c7e', 'PRO_REASON', 'gemini-2.5-pro-preview', 50, 3, 180000, '2025-12-08T06:02:08Z', '2025-12-08T06:05:08Z');
```

---

### 5. analysis_stocks (Ï¢ÖÎ™©Î≥Ñ ÏÉÅÏÑ∏)

```sql
-- Í∞Å Îã®Í≥ÑÏóêÏÑú Ï≤òÎ¶¨Îêú Ï¢ÖÎ™© Ï†ïÎ≥¥
CREATE TABLE analysis_stocks (
    id SERIAL PRIMARY KEY,
    batch_id UUID NOT NULL REFERENCES analysis_batches(id) ON DELETE CASCADE,
    step_name VARCHAR(50) NOT NULL,
        -- 'FETCH', 'FLASH_FILTER', 'PRO_REASON'
    stock_code VARCHAR(20) NOT NULL,
        -- '005930' (ÏÇºÏÑ±Ï†ÑÏûê)
    stock_name VARCHAR(100),
        -- 'ÏÇºÏÑ±Ï†ÑÏûê'
    status VARCHAR(20) NOT NULL,
        -- 'FETCHED', 'FILTERED', 'SELECTED'
    score NUMERIC(10, 4),
        -- Ï†êÏàò (0.0000 ~ 100.0000)
    filter_reason TEXT,
        -- Ïôú ÌÉàÎùΩÌñàÎäîÏßÄ / Ïôú ÏÑ†Ï†ïÎêòÏóàÎäîÏßÄ
    position_x FLOAT,
        -- ÏãúÍ∞ÅÌôî X Ï¢åÌëú (ÏòµÏÖò)
    position_y FLOAT,
        -- ÏãúÍ∞ÅÌôî Y Ï¢åÌëú (ÏòµÏÖò)
    metadata JSONB,
        -- Ï∂îÍ∞Ä Ï†ïÎ≥¥
    created_at TIMESTAMP NOT NULL DEFAULT NOW()
);

-- Ïù∏Îç±Ïä§
CREATE INDEX idx_stocks_batch ON analysis_stocks(batch_id);
CREATE INDEX idx_stocks_batch_step ON analysis_stocks(batch_id, step_name);
CREATE INDEX idx_stocks_status ON analysis_stocks(batch_id, status);
CREATE INDEX idx_stocks_score ON analysis_stocks(batch_id, score DESC);

-- ÏòàÏãú Îç∞Ïù¥ÌÑ∞
INSERT INTO analysis_stocks (batch_id, step_name, stock_code, stock_name, status, score, filter_reason) VALUES
    -- FETCH Îã®Í≥Ñ: 2500Í∞ú
    ('01932b75-8f0a-7c40-b5d4-2e8f3a1b9c7e', 'FETCH', '005930', 'ÏÇºÏÑ±Ï†ÑÏûê', 'FETCHED', 75.5, NULL),
    ('01932b75-8f0a-7c40-b5d4-2e8f3a1b9c7e', 'FETCH', '000660', 'SKÌïòÏù¥ÎãâÏä§', 'FETCHED', 82.3, NULL),
    -- ... (2498Í∞ú Îçî)

    -- FLASH_FILTER Îã®Í≥Ñ: 50Í∞ú (ÎÇòÎ®∏ÏßÄÎäî FILTERED)
    ('01932b75-8f0a-7c40-b5d4-2e8f3a1b9c7e', 'FLASH_FILTER', '005930', 'ÏÇºÏÑ±Ï†ÑÏûê', 'PASSED', 75.5, 'Î∞òÎèÑÏ≤¥ ÏÑπÌÑ∞ Í∏çÏ†ï, ÎØ∏Íµ≠ ÏßÄÌëú Ìò∏Ïû¨'),
    ('01932b75-8f0a-7c40-b5d4-2e8f3a1b9c7e', 'FLASH_FILTER', '000660', 'SKÌïòÏù¥ÎãâÏä§', 'PASSED', 82.3, 'HBM ÏàòÏöî Ï¶ùÍ∞Ä, AI Î∞òÎèÑÏ≤¥ Ìò∏Ìô©'),
    -- ... (48Í∞ú Îçî)

    -- PRO_REASON Îã®Í≥Ñ: 3Í∞ú (ÎÇòÎ®∏ÏßÄÎäî FILTERED)
    ('01932b75-8f0a-7c40-b5d4-2e8f3a1b9c7e', 'PRO_REASON', '005930', 'ÏÇºÏÑ±Ï†ÑÏûê', 'SELECTED', 75.5, 'Í∏ÄÎ°úÎ≤å Î∞òÎèÑÏ≤¥ ÏàòÏöî ÌöåÎ≥µ, ÌôòÏú® Ìò∏Ïû¨, Í∏∞Ïà†Ï†Å ÏßÄÌëú Ïö∞Ïàò'),
    ('01932b75-8f0a-7c40-b5d4-2e8f3a1b9c7e', 'PRO_REASON', '000660', 'SKÌïòÏù¥ÎãâÏä§', 'SELECTED', 82.3, 'HBM Ï†êÏú†Ïú® 1ÏúÑ, AI Î∞òÎèÑÏ≤¥ ÏµúÎåÄ ÏàòÌòúÏ£º'),
    ('01932b75-8f0a-7c40-b5d4-2e8f3a1b9c7e', 'PRO_REASON', '373220', 'LGÏóêÎÑàÏßÄÏÜîÎ£®ÏÖò', 'SELECTED', 68.9, 'Ï†ÑÍ∏∞Ï∞® ÏàòÏöî Ï¶ùÍ∞Ä, ÎØ∏Íµ≠ IRA ÏàòÌòú');
```

---

### 6. signal_stock_impacts (Ïã†Ìò∏ ‚Üí Ï¢ÖÎ™© ÏòÅÌñ•)

```sql
-- Ïñ¥Îñ§ Ïã†Ìò∏Í∞Ä Ïñ¥Îñ§ Ï¢ÖÎ™©Ïóê ÏòÅÌñ•ÏùÑ Ï§¨ÎäîÏßÄ
CREATE TABLE signal_stock_impacts (
    id SERIAL PRIMARY KEY,
    batch_id UUID NOT NULL REFERENCES analysis_batches(id) ON DELETE CASCADE,
    signal_id INT NOT NULL REFERENCES signal_logs(id) ON DELETE CASCADE,
    stock_code VARCHAR(20) NOT NULL,
    impact_type VARCHAR(20) NOT NULL,
        -- 'BOOST' (Í∏çÏ†ï), 'PENALTY' (Î∂ÄÏ†ï), 'NEUTRAL'
    impact_score FLOAT,
        -- Ï†êÏàò Ï°∞Ï†ïÍ∞í (-100.0 ~ +100.0)
    reasoning TEXT,
        -- AI ÏÑ§Î™Ö (Ïôú Ïù¥ Ïã†Ìò∏Í∞Ä Ïù¥ Ï¢ÖÎ™©Ïóê ÏòÅÌñ•?)
    created_at TIMESTAMP NOT NULL DEFAULT NOW()
);

-- Ïù∏Îç±Ïä§
CREATE INDEX idx_impacts_batch ON signal_stock_impacts(batch_id);
CREATE INDEX idx_impacts_signal ON signal_stock_impacts(signal_id);
CREATE INDEX idx_impacts_stock ON signal_stock_impacts(batch_id, stock_code);

-- ÏòàÏãú Îç∞Ïù¥ÌÑ∞
INSERT INTO signal_stock_impacts (batch_id, signal_id, stock_code, impact_type, impact_score, reasoning) VALUES
    -- ÏÇºÏÑ±Ï†ÑÏûêÏóê ÏòÅÌñ•
    ('01932b75-8f0a-7c40-b5d4-2e8f3a1b9c7e', 1, '005930', 'BOOST', 15.0,
     'Fed Í∏àÎ¶¨ ÎèôÍ≤∞Î°ú Î∞òÎèÑÏ≤¥ Ìà¨Ïûê ÌôòÍ≤Ω Í∞úÏÑ†, Îã¨Îü¨ ÏïΩÏÑ∏Î°ú ÏàòÏ∂ú Í≤ΩÏüÅÎ†• Ìñ•ÏÉÅ'),
    ('01932b75-8f0a-7c40-b5d4-2e8f3a1b9c7e', 2, '005930', 'PENALTY', -5.0,
     'WTI Ïú†Í∞Ä ÏÉÅÏäπÏúºÎ°ú ÏõêÏûêÏû¨ ÎπÑÏö© Ï¶ùÍ∞Ä, Ï†úÏ°∞ ÎßàÏßÑ ÏïïÎ∞ï'),
    ('01932b75-8f0a-7c40-b5d4-2e8f3a1b9c7e', 3, '005930', 'BOOST', 8.0,
     'Í∏à Í∞ÄÍ≤© ÏÉÅÏäπÏùÄ Î∂àÌôïÏã§ÏÑ± Ï¶ùÍ∞ÄÎ•º ÏùòÎØ∏ÌïòÎÇò, ÏïàÏ†ÑÏûêÏÇ∞ÏúºÎ°ú ÏÇºÏÑ±Ï†ÑÏûê ÏàòÌòú'),

    -- SKÌïòÏù¥ÎãâÏä§Ïóê ÏòÅÌñ•
    ('01932b75-8f0a-7c40-b5d4-2e8f3a1b9c7e', 1, '000660', 'BOOST', 20.0,
     'Fed Í∏àÎ¶¨ ÎèôÍ≤∞Î°ú AI Î∞òÎèÑÏ≤¥ Ìà¨Ïûê Í∞ÄÏÜçÌôî, HBM ÏàòÏöî Ï¶ùÍ∞Ä'),
    ('01932b75-8f0a-7c40-b5d4-2e8f3a1b9c7e', 2, '000660', 'NEUTRAL', 0.0,
     'Ïú†Í∞Ä ÏÉÅÏäπÏù¥ Î∞òÎèÑÏ≤¥ Ï†úÏ°∞ ÎπÑÏö©Ïóê ÎØ∏ÏπòÎäî ÏòÅÌñ• Ï†úÌïúÏ†Å');
```

---

### 7. control_events (Ï†úÏñ¥ Ïù¥Î≤§Ìä∏ Î°úÍ∑∏)

```sql
-- Í¥ÄÏ†ú ÏãúÏä§ÌÖúÏóêÏÑú Î∞úÏÉùÌïú ÏàòÎèô Ï†úÏñ¥ Ïù¥Î≤§Ìä∏
CREATE TABLE control_events (
    id SERIAL PRIMARY KEY,
    event_type VARCHAR(50) NOT NULL,
        -- 'BATCH_START', 'BATCH_STOP', 'BATCH_RESUME', 'CONFIG_CHANGE'
    batch_id UUID REFERENCES analysis_batches(id) ON DELETE SET NULL,
    user_id VARCHAR(100),
        -- Í¥ÄÎ¶¨Ïûê ID (ÏòµÏÖò)
    metadata JSONB,
        -- Ïù¥Î≤§Ìä∏ ÏÉÅÏÑ∏ Ï†ïÎ≥¥
    timestamp TIMESTAMP NOT NULL DEFAULT NOW()
);

-- Ïù∏Îç±Ïä§
CREATE INDEX idx_events_type ON control_events(event_type);
CREATE INDEX idx_events_batch ON control_events(batch_id);
CREATE INDEX idx_events_timestamp ON control_events(timestamp DESC);
```

---

### 8. performance_metrics (ÏÑ±Îä• Î©îÌä∏Î¶≠)

```sql
-- ÏÑ±Îä• Î™®ÎãàÌÑ∞ÎßÅÏö© Î©îÌä∏Î¶≠ (ÏãúÍ≥ÑÏó¥)
CREATE TABLE performance_metrics (
    id SERIAL PRIMARY KEY,
    metric_type VARCHAR(50) NOT NULL,
        -- 'processing_time', 'error_rate', 'throughput', 'db_query_time'
    metric_name VARCHAR(100) NOT NULL,
        -- 'flash_filter_avg_ms', 'pro_reason_p95_ms', etc.
    value NUMERIC(20, 4) NOT NULL,
    unit VARCHAR(20),
        -- 'ms', '%', 'count'
    batch_id UUID REFERENCES analysis_batches(id) ON DELETE SET NULL,
    metadata JSONB,
    timestamp TIMESTAMP NOT NULL DEFAULT NOW()
);

-- Ïù∏Îç±Ïä§
CREATE INDEX idx_metrics_type ON performance_metrics(metric_type);
CREATE INDEX idx_metrics_timestamp ON performance_metrics(timestamp DESC);

-- ÏãúÍ≥ÑÏó¥ Îç∞Ïù¥ÌÑ∞ ÏµúÏ†ÅÌôî (ÏÑ†ÌÉù: TimescaleDB Hypertable)
-- SELECT create_hypertable('performance_metrics', 'timestamp');
```

---

## Í¥ÄÍ≥Ñ Îã§Ïù¥Ïñ¥Í∑∏Îû®

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                       Entity Relationship                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                     ‚îÇ
‚îÇ  signal_sources (ÎßàÏä§ÌÑ∞)                                            ‚îÇ
‚îÇ       ‚îÇ                                                             ‚îÇ
‚îÇ       ‚îÇ 1:N                                                         ‚îÇ
‚îÇ       ‚ñº                                                             ‚îÇ
‚îÇ  signal_logs ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                                 ‚îÇ
‚îÇ       ‚îÇ           ‚îÇ                                                 ‚îÇ
‚îÇ       ‚îÇ N:1       ‚îÇ 1:N                                             ‚îÇ
‚îÇ       ‚ñº           ‚ñº                                                 ‚îÇ
‚îÇ  analysis_batches ‚óÑ‚îÄ‚îÄ signal_stock_impacts                          ‚îÇ
‚îÇ       ‚îÇ                    ‚îÇ                                        ‚îÇ
‚îÇ       ‚îÇ 1:N                ‚îÇ N:1                                    ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                             ‚îÇ
‚îÇ       ‚îÇ                               ‚îÇ                             ‚îÇ
‚îÇ       ‚ñº                               ‚ñº                             ‚îÇ
‚îÇ  analysis_steps              analysis_stocks                        ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ  control_events (ÎèÖÎ¶Ω)                                              ‚îÇ
‚îÇ  performance_metrics (ÎèÖÎ¶Ω)                                         ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Ïù∏Îç±Ïä§ Ï†ÑÎûµ

### 1. Ï°∞Ìöå Ìå®ÌÑ¥Î≥Ñ ÏµúÏ†ÅÌôî

```sql
-- [Ìå®ÌÑ¥ 1] ÏµúÍ∑º Î∞∞Ïπò Î™©Î°ù Ï°∞Ìöå
-- Query: SELECT * FROM analysis_batches ORDER BY started_at DESC LIMIT 20;
CREATE INDEX idx_batches_started_at ON analysis_batches(started_at DESC);

-- [Ìå®ÌÑ¥ 2] ÌäπÏ†ï Î∞∞ÏπòÏùò Î™®Îì† Ïã†Ìò∏ Ï°∞Ìöå
-- Query: SELECT * FROM signal_logs WHERE batch_id = ?;
CREATE INDEX idx_signals_batch ON signal_logs(batch_id);

-- [Ìå®ÌÑ¥ 3] ÌäπÏ†ï Î∞∞ÏπòÏùò ÏµúÏ¢Ö ÏÑ†Ï†ï Ï¢ÖÎ™©
-- Query: SELECT * FROM analysis_stocks WHERE batch_id = ? AND step_name = 'PRO_REASON' AND status = 'SELECTED';
CREATE INDEX idx_stocks_batch_step_status ON analysis_stocks(batch_id, step_name, status);

-- [Ìå®ÌÑ¥ 4] Ï¢ÖÎ™©Ïóê ÏòÅÌñ•ÏùÑ Ï§Ä Ïã†Ìò∏ Ï∂îÏ†Å
-- Query: SELECT * FROM signal_stock_impacts WHERE batch_id = ? AND stock_code = ?;
CREATE INDEX idx_impacts_batch_stock ON signal_stock_impacts(batch_id, stock_code);

-- [Ìå®ÌÑ¥ 5] ÏÑ±Îä• Î©îÌä∏Î¶≠ ÏãúÍ≥ÑÏó¥ Ï°∞Ìöå
-- Query: SELECT * FROM performance_metrics WHERE metric_type = ? AND timestamp >= ?;
CREATE INDEX idx_metrics_type_timestamp ON performance_metrics(metric_type, timestamp DESC);
```

### 2. Partial Index (Ï°∞Í±¥Î∂Ä Ïù∏Îç±Ïä§)

```sql
-- Ïã§Ìñâ Ï§ëÏù∏ Î∞∞ÏπòÎßå Îπ†Î•¥Í≤å Ï°∞Ìöå
CREATE INDEX idx_batches_running ON analysis_batches(started_at DESC)
WHERE status = 'RUNNING';

-- ÌôúÏÑ± Ïã†Ìò∏ ÏÜåÏä§Îßå Ïù∏Îç±Ïä§
CREATE INDEX idx_sources_active ON signal_sources(category, region)
WHERE is_active = TRUE;
```

### 3. Covering Index (Ïª§Î≤ÑÎßÅ Ïù∏Îç±Ïä§)

```sql
-- ÏßëÍ≥Ñ ÏøºÎ¶¨ ÏµúÏ†ÅÌôî (INDEX ONLY SCAN)
CREATE INDEX idx_steps_batch_times ON analysis_steps(batch_id, step_name)
INCLUDE (processing_time_ms, started_at, completed_at);
```

---

## ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò

### Alembic ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò Ïä§ÌÅ¨Î¶ΩÌä∏

```python
# alembic/versions/2025_12_08_ai_visualizer.py
"""
AI Visualizer Schema

Revision ID: abc123def456
Revises: previous_revision
Create Date: 2025-12-08 12:00:00
"""

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers
revision = 'abc123def456'
down_revision = 'previous_revision'
branch_labels = None
depends_on = None


def upgrade():
    # 1. analysis_batches
    op.create_table(
        'analysis_batches',
        sa.Column('id', postgresql.UUID(as_uuid=True), primary_key=True, server_default=sa.text('gen_random_uuid()')),
        sa.Column('started_at', sa.TIMESTAMP(), nullable=False, server_default=sa.text('NOW()')),
        sa.Column('completed_at', sa.TIMESTAMP(), nullable=True),
        sa.Column('status', sa.VARCHAR(20), nullable=False, server_default='RUNNING'),
        sa.Column('trigger_type', sa.VARCHAR(20), nullable=False),
        sa.Column('error_message', sa.TEXT(), nullable=True),
        sa.Column('metadata', postgresql.JSONB(), nullable=True),
        sa.Column('created_at', sa.TIMESTAMP(), nullable=False, server_default=sa.text('NOW()')),
        sa.Column('updated_at', sa.TIMESTAMP(), nullable=False, server_default=sa.text('NOW()')),
    )
    op.create_index('idx_batches_status', 'analysis_batches', ['status'])
    op.create_index('idx_batches_started_at', 'analysis_batches', ['started_at'], postgresql_ops={'started_at': 'DESC'})

    # 2. signal_sources
    op.create_table(
        'signal_sources',
        sa.Column('id', sa.INTEGER(), primary_key=True, autoincrement=True),
        sa.Column('source_code', sa.VARCHAR(50), unique=True, nullable=False),
        sa.Column('source_name', sa.VARCHAR(100), nullable=False),
        sa.Column('category', sa.VARCHAR(50), nullable=False),
        sa.Column('region', sa.VARCHAR(50), nullable=False),
        sa.Column('icon', sa.VARCHAR(10), nullable=True),
        sa.Column('position_x', sa.FLOAT(), nullable=True),
        sa.Column('position_y', sa.FLOAT(), nullable=True),
        sa.Column('is_active', sa.BOOLEAN(), nullable=False, server_default='TRUE'),
        sa.Column('created_at', sa.TIMESTAMP(), nullable=False, server_default=sa.text('NOW()')),
        sa.Column('updated_at', sa.TIMESTAMP(), nullable=False, server_default=sa.text('NOW()')),
    )

    # 3. signal_logs
    op.create_table(
        'signal_logs',
        sa.Column('id', sa.INTEGER(), primary_key=True, autoincrement=True),
        sa.Column('batch_id', postgresql.UUID(as_uuid=True), sa.ForeignKey('analysis_batches.id', ondelete='CASCADE'), nullable=False),
        sa.Column('source_code', sa.VARCHAR(50), sa.ForeignKey('signal_sources.source_code'), nullable=False),
        sa.Column('signal_type', sa.VARCHAR(20), nullable=False),
        sa.Column('title', sa.VARCHAR(500), nullable=True),
        sa.Column('content', sa.TEXT(), nullable=True),
        sa.Column('sentiment', sa.VARCHAR(20), nullable=True),
        sa.Column('sentiment_score', sa.FLOAT(), nullable=True),
        sa.Column('impact_level', sa.VARCHAR(20), nullable=True),
        sa.Column('raw_value', postgresql.JSONB(), nullable=True),
        sa.Column('fetched_at', sa.TIMESTAMP(), nullable=False, server_default=sa.text('NOW()')),
    )
    op.create_index('idx_signals_batch', 'signal_logs', ['batch_id'])

    # 4. analysis_steps
    op.create_table(
        'analysis_steps',
        sa.Column('id', sa.INTEGER(), primary_key=True, autoincrement=True),
        sa.Column('batch_id', postgresql.UUID(as_uuid=True), sa.ForeignKey('analysis_batches.id', ondelete='CASCADE'), nullable=False),
        sa.Column('step_name', sa.VARCHAR(50), nullable=False),
        sa.Column('model_used', sa.VARCHAR(50), nullable=True),
        sa.Column('input_count', sa.INTEGER(), nullable=True),
        sa.Column('output_count', sa.INTEGER(), nullable=True),
        sa.Column('processing_time_ms', sa.INTEGER(), nullable=True),
        sa.Column('started_at', sa.TIMESTAMP(), nullable=False, server_default=sa.text('NOW()')),
        sa.Column('completed_at', sa.TIMESTAMP(), nullable=True),
        sa.Column('error_message', sa.TEXT(), nullable=True),
        sa.Column('metadata', postgresql.JSONB(), nullable=True),
    )
    op.create_index('idx_steps_batch', 'analysis_steps', ['batch_id'])

    # 5. analysis_stocks
    op.create_table(
        'analysis_stocks',
        sa.Column('id', sa.INTEGER(), primary_key=True, autoincrement=True),
        sa.Column('batch_id', postgresql.UUID(as_uuid=True), sa.ForeignKey('analysis_batches.id', ondelete='CASCADE'), nullable=False),
        sa.Column('step_name', sa.VARCHAR(50), nullable=False),
        sa.Column('stock_code', sa.VARCHAR(20), nullable=False),
        sa.Column('stock_name', sa.VARCHAR(100), nullable=True),
        sa.Column('status', sa.VARCHAR(20), nullable=False),
        sa.Column('score', sa.NUMERIC(10, 4), nullable=True),
        sa.Column('filter_reason', sa.TEXT(), nullable=True),
        sa.Column('position_x', sa.FLOAT(), nullable=True),
        sa.Column('position_y', sa.FLOAT(), nullable=True),
        sa.Column('metadata', postgresql.JSONB(), nullable=True),
        sa.Column('created_at', sa.TIMESTAMP(), nullable=False, server_default=sa.text('NOW()')),
    )
    op.create_index('idx_stocks_batch', 'analysis_stocks', ['batch_id'])
    op.create_index('idx_stocks_batch_step', 'analysis_stocks', ['batch_id', 'step_name'])

    # 6. signal_stock_impacts
    op.create_table(
        'signal_stock_impacts',
        sa.Column('id', sa.INTEGER(), primary_key=True, autoincrement=True),
        sa.Column('batch_id', postgresql.UUID(as_uuid=True), sa.ForeignKey('analysis_batches.id', ondelete='CASCADE'), nullable=False),
        sa.Column('signal_id', sa.INTEGER(), sa.ForeignKey('signal_logs.id', ondelete='CASCADE'), nullable=False),
        sa.Column('stock_code', sa.VARCHAR(20), nullable=False),
        sa.Column('impact_type', sa.VARCHAR(20), nullable=False),
        sa.Column('impact_score', sa.FLOAT(), nullable=True),
        sa.Column('reasoning', sa.TEXT(), nullable=True),
        sa.Column('created_at', sa.TIMESTAMP(), nullable=False, server_default=sa.text('NOW()')),
    )
    op.create_index('idx_impacts_batch', 'signal_stock_impacts', ['batch_id'])

    # 7. control_events
    op.create_table(
        'control_events',
        sa.Column('id', sa.INTEGER(), primary_key=True, autoincrement=True),
        sa.Column('event_type', sa.VARCHAR(50), nullable=False),
        sa.Column('batch_id', postgresql.UUID(as_uuid=True), sa.ForeignKey('analysis_batches.id', ondelete='SET NULL'), nullable=True),
        sa.Column('user_id', sa.VARCHAR(100), nullable=True),
        sa.Column('metadata', postgresql.JSONB(), nullable=True),
        sa.Column('timestamp', sa.TIMESTAMP(), nullable=False, server_default=sa.text('NOW()')),
    )

    # 8. performance_metrics
    op.create_table(
        'performance_metrics',
        sa.Column('id', sa.INTEGER(), primary_key=True, autoincrement=True),
        sa.Column('metric_type', sa.VARCHAR(50), nullable=False),
        sa.Column('metric_name', sa.VARCHAR(100), nullable=False),
        sa.Column('value', sa.NUMERIC(20, 4), nullable=False),
        sa.Column('unit', sa.VARCHAR(20), nullable=True),
        sa.Column('batch_id', postgresql.UUID(as_uuid=True), sa.ForeignKey('analysis_batches.id', ondelete='SET NULL'), nullable=True),
        sa.Column('metadata', postgresql.JSONB(), nullable=True),
        sa.Column('timestamp', sa.TIMESTAMP(), nullable=False, server_default=sa.text('NOW()')),
    )
    op.create_index('idx_metrics_timestamp', 'performance_metrics', ['timestamp'], postgresql_ops={'timestamp': 'DESC'})


def downgrade():
    op.drop_table('performance_metrics')
    op.drop_table('control_events')
    op.drop_table('signal_stock_impacts')
    op.drop_table('analysis_stocks')
    op.drop_table('analysis_steps')
    op.drop_table('signal_logs')
    op.drop_table('signal_sources')
    op.drop_table('analysis_batches')
```

### ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò Ïã§Ìñâ

```bash
# ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò ÏÉùÏÑ±
alembic revision -m "ai_visualizer_schema"

# ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò Ï†ÅÏö©
alembic upgrade head

# Î°§Î∞± (ÌïÑÏöî Ïãú)
alembic downgrade -1
```

---

## SQLAlchemy Î™®Îç∏

```python
# src/database/models.py
from sqlalchemy import Column, Integer, String, Float, Boolean, Text, TIMESTAMP, ForeignKey
from sqlalchemy.dialects.postgresql import UUID, JSONB
from sqlalchemy.orm import relationship
from sqlalchemy.sql import func
import uuid

from database import Base


class AnalysisBatch(Base):
    __tablename__ = 'analysis_batches'

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    started_at = Column(TIMESTAMP, nullable=False, server_default=func.now())
    completed_at = Column(TIMESTAMP)
    status = Column(String(20), nullable=False, default='RUNNING')
    trigger_type = Column(String(20), nullable=False)
    error_message = Column(Text)
    metadata = Column(JSONB)
    created_at = Column(TIMESTAMP, nullable=False, server_default=func.now())
    updated_at = Column(TIMESTAMP, nullable=False, server_default=func.now(), onupdate=func.now())

    # Í¥ÄÍ≥Ñ
    steps = relationship('AnalysisStep', back_populates='batch', cascade='all, delete-orphan')
    signals = relationship('SignalLog', back_populates='batch', cascade='all, delete-orphan')
    stocks = relationship('AnalysisStock', back_populates='batch', cascade='all, delete-orphan')


class SignalSource(Base):
    __tablename__ = 'signal_sources'

    id = Column(Integer, primary_key=True, autoincrement=True)
    source_code = Column(String(50), unique=True, nullable=False)
    source_name = Column(String(100), nullable=False)
    category = Column(String(50), nullable=False)
    region = Column(String(50), nullable=False)
    icon = Column(String(10))
    position_x = Column(Float)
    position_y = Column(Float)
    is_active = Column(Boolean, default=True)
    created_at = Column(TIMESTAMP, nullable=False, server_default=func.now())
    updated_at = Column(TIMESTAMP, nullable=False, server_default=func.now(), onupdate=func.now())

    # Í¥ÄÍ≥Ñ
    signals = relationship('SignalLog', back_populates='source')


class SignalLog(Base):
    __tablename__ = 'signal_logs'

    id = Column(Integer, primary_key=True, autoincrement=True)
    batch_id = Column(UUID(as_uuid=True), ForeignKey('analysis_batches.id', ondelete='CASCADE'), nullable=False)
    source_code = Column(String(50), ForeignKey('signal_sources.source_code'), nullable=False)
    signal_type = Column(String(20), nullable=False)
    title = Column(String(500))
    content = Column(Text)
    sentiment = Column(String(20))
    sentiment_score = Column(Float)
    impact_level = Column(String(20))
    raw_value = Column(JSONB)
    fetched_at = Column(TIMESTAMP, nullable=False, server_default=func.now())

    # Í¥ÄÍ≥Ñ
    batch = relationship('AnalysisBatch', back_populates='signals')
    source = relationship('SignalSource', back_populates='signals')
    impacts = relationship('SignalStockImpact', back_populates='signal', cascade='all, delete-orphan')


# ... (ÎÇòÎ®∏ÏßÄ Î™®Îç∏ ÏÉùÎûµ)
```

---

## Îã§Ïùå Îã®Í≥Ñ

1. **ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò Ïã§Ìñâ**: `alembic upgrade head`
2. **Ï¥àÍ∏∞ Îç∞Ïù¥ÌÑ∞ ÏûÖÎ†•**: signal_sources ÎßàÏä§ÌÑ∞ Îç∞Ïù¥ÌÑ∞
3. **Fetcher ÏàòÏ†ï**: signal_logs Ï†ÄÏû• Î°úÏßÅ Ï∂îÍ∞Ä
4. **Brain ÏàòÏ†ï**: analysis_steps, analysis_stocks Ï†ÄÏû•

---

**ÏûëÏÑ±Ïùº**: 2025-12-08
**ÏûëÏÑ±Ïûê**: wonny
**Î≤ÑÏ†Ñ**: 1.0.0
