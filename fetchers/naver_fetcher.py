"""
AEGIS v3.0 - Naver News Fetcher
ë„¤ì´ë²„ ê¸ˆìœµ ë‰´ìŠ¤ ìˆ˜ì§‘ (ì£¼ë§ í—¤ë“œë¼ì¸)
"""
import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import logging

logger = logging.getLogger("NaverFetcher")


class NaverFetcher:
    """
    ë„¤ì´ë²„ ê¸ˆìœµ ë‰´ìŠ¤ ìˆ˜ì§‘ (ì›¹ ìŠ¤í¬ë˜í•‘)
    """

    BASE_URL = "https://finance.naver.com/news/news_list.naver"

    def __init__(self):
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
        }
        logger.info("âœ… NaverFetcher initialized")

    def get_weekend_news(self, max_articles=10):
        """
        ì£¼ë§ ì£¼ìš” ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ìˆ˜ì§‘

        Args:
            max_articles: ìµœëŒ€ ìˆ˜ì§‘ ê¸°ì‚¬ ìˆ˜

        Returns:
            str: ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ìš”ì•½ í…ìŠ¤íŠ¸
        """
        try:
            # ë„¤ì´ë²„ ê¸ˆìœµ ë‰´ìŠ¤ ì†ë³´ í˜ì´ì§€
            url = f"{self.BASE_URL}?mode=LSS2D&section_id=101&section_id2=258"

            response = requests.get(url, headers=self.headers, timeout=10)
            response.raise_for_status()

            soup = BeautifulSoup(response.text, "html.parser")

            # ë‰´ìŠ¤ ì œëª© ì¶”ì¶œ
            headlines = []
            news_items = soup.select("dt.articleSubject a")

            for i, item in enumerate(news_items[:max_articles]):
                title = item.get_text(strip=True)
                headlines.append(f"{i+1}. {title}")

            if not headlines:
                logger.warning("âš ï¸  No news headlines found")
                return "No recent news available."

            logger.info(f"ğŸ“° Collected {len(headlines)} news headlines")
            return "\n".join(headlines)

        except Exception as e:
            logger.error(f"âŒ Failed to fetch Naver news: {e}")
            return "Failed to fetch news."

    def get_market_briefing(self):
        """
        ì¦ì‹œ ë¸Œë¦¬í•‘ ìˆ˜ì§‘ (ì¦ê¶Œì‚¬ ë¦¬í¬íŠ¸ ìš”ì•½)

        Returns:
            str: ë¸Œë¦¬í•‘ í…ìŠ¤íŠ¸
        """
        try:
            # ì¦ê¶Œì‚¬ ë¦¬í¬íŠ¸ í˜ì´ì§€
            url = f"{self.BASE_URL}?mode=LSS3D&section_id=101&section_id2=258&section_id3=401"

            response = requests.get(url, headers=self.headers, timeout=10)
            response.raise_for_status()

            soup = BeautifulSoup(response.text, "html.parser")

            briefings = []
            items = soup.select("dt.articleSubject a")

            for i, item in enumerate(items[:5]):
                title = item.get_text(strip=True)
                briefings.append(f"- {title}")

            if not briefings:
                return "No market briefing available."

            logger.info(f"ğŸ“Š Collected {len(briefings)} briefings")
            return "\n".join(briefings)

        except Exception as e:
            logger.error(f"âŒ Failed to fetch briefing: {e}")
            return "Failed to fetch briefing."

    def get_sector_news(self, sector="ë°˜ë„ì²´"):
        """
        íŠ¹ì • ì„¹í„° ë‰´ìŠ¤ ìˆ˜ì§‘

        Args:
            sector: ê²€ìƒ‰í•  ì„¹í„° í‚¤ì›Œë“œ (ì˜ˆ: "ë°˜ë„ì²´", "2ì°¨ì „ì§€", "ë°”ì´ì˜¤")

        Returns:
            str: ì„¹í„° ê´€ë ¨ ë‰´ìŠ¤ í—¤ë“œë¼ì¸
        """
        try:
            # ë„¤ì´ë²„ ê¸ˆìœµ ë‰´ìŠ¤ ê²€ìƒ‰
            search_url = "https://finance.naver.com/news/news_search.naver"
            params = {
                "q": sector,
                "x": 0,
                "y": 0
            }

            response = requests.get(search_url, params=params, headers=self.headers, timeout=10)
            response.raise_for_status()

            soup = BeautifulSoup(response.text, "html.parser")

            headlines = []
            items = soup.select("dt.articleSubject a")

            for i, item in enumerate(items[:5]):
                title = item.get_text(strip=True)
                headlines.append(f"- {title}")

            if not headlines:
                return f"No news for sector '{sector}'."

            logger.info(f"ğŸ“° Collected {len(headlines)} news for '{sector}'")
            return f"[{sector} ê´€ë ¨ ë‰´ìŠ¤]\n" + "\n".join(headlines)

        except Exception as e:
            logger.error(f"âŒ Failed to fetch sector news: {e}")
            return f"Failed to fetch news for '{sector}'."

    def get_hot_themes(self, max_themes=20):
        """
        ë„¤ì´ë²„ ê¸ˆìœµ ì¸ê¸° í…Œë§ˆ ìˆ˜ì§‘

        Returns:
            list: [{
                "theme_name": str,
                "change_rate": float,
                "stocks": list[str]  # ëŒ€í‘œ ì¢…ëª©ë“¤
            }]
        """
        try:
            # ë„¤ì´ë²„ ê¸ˆìœµ í…Œë§ˆ í˜ì´ì§€
            url = "https://finance.naver.com/sise/theme.naver"

            response = requests.get(url, headers=self.headers, timeout=10)
            response.raise_for_status()

            soup = BeautifulSoup(response.text, "html.parser")

            themes = []
            theme_items = soup.select("table.type_1 tr")[2:]  # í—¤ë” ì œì™¸

            for item in theme_items[:max_themes]:
                try:
                    cols = item.select("td")
                    if len(cols) < 4:
                        continue

                    # í…Œë§ˆëª…
                    theme_link = cols[0].select_one("a")
                    if not theme_link:
                        continue

                    theme_name = theme_link.get_text(strip=True)

                    # ë“±ë½ë¥ 
                    change_text = cols[3].get_text(strip=True)
                    change_rate = float(change_text.replace("%", "").replace("+", "").replace(",", ""))

                    # í…Œë§ˆ ìƒì„¸ í˜ì´ì§€ì—ì„œ ëŒ€í‘œ ì¢…ëª© ìˆ˜ì§‘
                    theme_url = "https://finance.naver.com" + theme_link.get("href")
                    stocks = self._get_theme_stocks(theme_url)

                    themes.append({
                        "theme_name": theme_name,
                        "change_rate": change_rate,
                        "stocks": stocks
                    })

                except Exception as e:
                    logger.debug(f"í…Œë§ˆ íŒŒì‹± ì‹¤íŒ¨: {e}")
                    continue

            logger.info(f"ğŸ”¥ Collected {len(themes)} hot themes")
            return themes

        except Exception as e:
            logger.error(f"âŒ Failed to fetch themes: {e}")
            return []

    def _get_theme_stocks(self, theme_url, max_stocks=5):
        """í…Œë§ˆë³„ ëŒ€í‘œ ì¢…ëª© ìˆ˜ì§‘"""
        try:
            response = requests.get(theme_url, headers=self.headers, timeout=10)
            response.raise_for_status()

            soup = BeautifulSoup(response.text, "html.parser")

            stocks = []
            stock_items = soup.select("table.type_5 tr")[2:]  # í—¤ë” ì œì™¸

            for item in stock_items[:max_stocks]:
                try:
                    cols = item.select("td")
                    if len(cols) < 2:
                        continue

                    stock_name = cols[1].get_text(strip=True)
                    if stock_name:
                        stocks.append(stock_name)

                except Exception:
                    continue

            return stocks

        except Exception as e:
            logger.debug(f"í…Œë§ˆ ì¢…ëª© ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return []


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    logging.basicConfig(level=logging.INFO)

    fetcher = NaverFetcher()

    print("\n" + "="*60)
    print("ğŸ“° Weekend News Test")
    print("="*60)
    news = fetcher.get_weekend_news()
    print(news)

    print("\n" + "="*60)
    print("ğŸ“Š Market Briefing Test")
    print("="*60)
    briefing = fetcher.get_market_briefing()
    print(briefing)

    print("\n" + "="*60)
    print("ğŸ“° Sector News Test (ë°˜ë„ì²´)")
    print("="*60)
    sector_news = fetcher.get_sector_news("ë°˜ë„ì²´")
    print(sector_news)
